import json
from pathlib import Path
from datetime import date, timedelta, datetime

import numpy as np
import pandas as pd
import streamlit as st
import xgboost as xgb

APP_DIR = Path(__file__).resolve().parent
MODELS_DIR = APP_DIR / "models"
DATA_DIR = APP_DIR / "data"

ARR_MODEL_PATH = MODELS_DIR / "model_A_timeseries.json"
SVC_MODEL_PATH = MODELS_DIR / "model_A_service_30min.json"
WAIT_MODEL_PATH = MODELS_DIR / "model_A_waittime_30min.json"
WAITP90_MODEL_PATH = MODELS_DIR / "model_A_waittime_p90_30min.json"

ARR_COLS_PATH = MODELS_DIR / "columns_A_timeseries.json"
MULTI_COLS_PATH = MODELS_DIR / "columns_A_multi_30min.json"

BASELINE_PATH = MODELS_DIR / "baseline_tables_mds.json"
CALIB_PATH = MODELS_DIR / "wait_calibration.json"

HOLIDAY_CSV_PATH = DATA_DIR / "syukujitsu.csv"

OPEN_HOUR = 8
CLOSE_HOUR = 18
FREQ_MIN = 30
SLOT_MINUTES = 30.0

WEATHER_CATS = ["æ™´", "æ›‡", "é›¨", "é›ª"]

# ---------------- holiday ----------------
def _load_holidays() -> set:
    if not HOLIDAY_CSV_PATH.exists():
        return set()
    df = pd.read_csv(HOLIDAY_CSV_PATH, encoding="utf-8", engine="python")
    col = None
    for c in df.columns:
        if str(c).strip().lower() in ["date", "æ—¥ä»˜"]:
            col = c
            break
    if col is None:
        col = df.columns[0]
    s = pd.to_datetime(df[col], errors="coerce").dropna().dt.date
    return set(s.tolist())

HOLIDAYS = _load_holidays()

def is_holiday(d: date) -> bool:
    if d.weekday() >= 5:
        return True
    if d in HOLIDAYS:
        return True
    if (d.month == 12 and d.day >= 29) or (d.month == 1 and d.day <= 3):
        return True
    return False

def normalize_weather(text: str) -> str:
    s = str(text) if text is not None else ""
    if "é›ª" in s: return "é›ª"
    if "é›¨" in s: return "é›¨"
    if "æ›‡" in s: return "æ›‡"
    if "æ™´" in s: return "æ™´"
    return "æ›‡"

def slot_id(ts: datetime) -> int:
    minutes = ts.hour * 60 + ts.minute
    base = 8 * 60
    return int((minutes - base) // 30)

def baseline_key(ts: datetime) -> str:
    return f"{ts.month}_{ts.weekday()}_{slot_id(ts)}"

def in_peak(ts: datetime) -> bool:
    # 8:30ã€œ11:00
    h, m = ts.hour, ts.minute
    after = (h > 8) or (h == 8 and m >= 30)
    before = (h < 11) or (h == 11 and m == 0)
    return after and before

@st.cache_resource
def load_assets():
    arr_cols = json.loads(ARR_COLS_PATH.read_text(encoding="utf-8"))
    multi_cols = json.loads(MULTI_COLS_PATH.read_text(encoding="utf-8"))

    arr_bst = xgb.Booster(); arr_bst.load_model(str(ARR_MODEL_PATH))
    svc_bst = xgb.Booster(); svc_bst.load_model(str(SVC_MODEL_PATH))
    wait_bst = xgb.Booster(); wait_bst.load_model(str(WAIT_MODEL_PATH))
    wp90_bst = xgb.Booster(); wp90_bst.load_model(str(WAITP90_MODEL_PATH))

    baseline = json.loads(BASELINE_PATH.read_text(encoding="utf-8"))
    calib = json.loads(CALIB_PATH.read_text(encoding="utf-8"))
    return arr_bst, arr_cols, svc_bst, wait_bst, wp90_bst, multi_cols, baseline, calib

def _make_zero_df(cols):
    return pd.DataFrame({c: [0] for c in cols})

def _predict_booster(booster: xgb.Booster, cols, df: pd.DataFrame) -> float:
    X = df[cols].copy()
    for c in X.columns:
        X[c] = pd.to_numeric(X[c], errors="coerce").fillna(0)
    dmat = xgb.DMatrix(X, feature_names=list(cols))
    pred = booster.predict(dmat)
    return float(pred[0])

def get_base(baseline, kind: str, key: str, stat="median", default=0.0):
    try:
        return float(baseline.get(kind, {}).get(key, {}).get(stat, default))
    except Exception:
        return float(default)

def clip(x: float, lo: float, hi: float) -> float:
    return float(np.clip(x, lo, hi))

def simulate_one_day(target_date: date, total_outpatient_count: int, weather: str) -> pd.DataFrame:
    arr_bst, arr_cols, svc_bst, wait_bst, wp90_bst, multi_cols, baseline, calib = load_assets()

    is_h = is_holiday(target_date)
    prev = target_date - timedelta(days=1)
    is_prev_h = is_holiday(prev)

    start = datetime(target_date.year, target_date.month, target_date.day, OPEN_HOUR, 0)
    end = datetime(target_date.year, target_date.month, target_date.day, CLOSE_HOUR, 0)
    slots = pd.date_range(start=start, end=end, freq=f"{FREQ_MIN}min").to_pydatetime().tolist()
    slots = [t for t in slots if t.time() != end.time()]  # 18:00é™¤å¤–

    # state
    queue_start = 0.0

    # lags
    arr_lag_30=arr_lag_60=arr_lag_90=0.0
    svc_lag_30=svc_lag_60=svc_lag_90=0.0

    wcat = normalize_weather(weather)

    a = float(calib.get("a", 1.0))
    b = float(calib.get("b", 0.0))
    alpha_base = float(calib.get("alpha_base", 0.60))
    alpha_peak = float(calib.get("alpha_peak", 0.25))

    results = []
    for ts in slots:
        key = baseline_key(ts)

        # ---------- arrivals (log1p) ----------
        af = _make_zero_df(arr_cols)
        for col, val in [
            ("hour", ts.hour), ("minute", ts.minute),
            ("æœˆ", ts.month),
            ("é€±å›æ•°", int((ts.day - 1)//7 + 1)),
            ("å‰æ—¥ç¥æ—¥ãƒ•ãƒ©ã‚°", int(is_prev_h)),
            ("total_outpatient_count", int(total_outpatient_count)),
            ("is_holiday", int(is_h)),
        ]:
            if col in af.columns:
                af.loc[0, col] = val

        dc = f"dayofweek_{ts.weekday()}"
        if dc in af.columns: af.loc[0, dc] = 1
        wc = f"å¤©æ°—ã‚«ãƒ†ã‚´ãƒª_{wcat}"
        if wc in af.columns: af.loc[0, wc] = 1
        if "é›¨ãƒ•ãƒ©ã‚°" in af.columns: af.loc[0, "é›¨ãƒ•ãƒ©ã‚°"] = 1 if wcat=="é›¨" else 0
        if "é›ªãƒ•ãƒ©ã‚°" in af.columns: af.loc[0, "é›ªãƒ•ãƒ©ã‚°"] = 1 if wcat=="é›ª" else 0

        for col, val in [
            ("arr_lag_30", arr_lag_30), ("arr_lag_60", arr_lag_60), ("arr_lag_90", arr_lag_90),
            ("arr_roll_60", (arr_lag_30+arr_lag_60)/2.0),
            ("queue_at_start_truth", queue_start),
            ("queue_at_start_of_slot", queue_start),
        ]:
            if col in af.columns:
                af.loc[0, col] = val

        arr_log = _predict_booster(arr_bst, arr_cols, af)
        arr_pred = max(0.0, float(np.expm1(arr_log)))

        arr_med = get_base(baseline, "arr", key, "median", default=arr_pred)
        # arrivalsã¯è»½ãbaselineå¯„ã›ï¼ˆéå­¦ç¿’ã®ãƒ–ãƒ¬å¯¾ç­–ï¼‰
        arr = 0.85*arr_pred + 0.15*arr_med

        # ---------- multi features ----------
        mf = _make_zero_df(multi_cols)
        for col, val in [
            ("hour", ts.hour), ("minute", ts.minute),
            ("æœˆ", ts.month),
            ("é€±å›æ•°", int((ts.day - 1)//7 + 1)),
            ("å‰æ—¥ç¥æ—¥ãƒ•ãƒ©ã‚°", int(is_prev_h)),
            ("total_outpatient_count", int(total_outpatient_count)),
            ("is_holiday", int(is_h)),
            ("reception_count", arr),
            ("queue_at_start_truth", queue_start),
            ("queue_at_start_of_slot", queue_start),
            ("svc_lag_30", svc_lag_30), ("svc_lag_60", svc_lag_60), ("svc_lag_90", svc_lag_90),
            ("svc_roll_60", (svc_lag_30+svc_lag_60)/2.0),
        ]:
            if col in mf.columns:
                mf.loc[0, col] = val

        dc2 = f"dayofweek_{ts.weekday()}"
        if dc2 in mf.columns: mf.loc[0, dc2] = 1
        wc2 = f"å¤©æ°—ã‚«ãƒ†ã‚´ãƒª_{wcat}"
        if wc2 in mf.columns: mf.loc[0, wc2] = 1
        if "é›¨ãƒ•ãƒ©ã‚°" in mf.columns: mf.loc[0, "é›¨ãƒ•ãƒ©ã‚°"] = 1 if wcat=="é›¨" else 0
        if "é›ªãƒ•ãƒ©ã‚°" in mf.columns: mf.loc[0, "é›ªãƒ•ãƒ©ã‚°"] = 1 if wcat=="é›ª" else 0

        # ---------- service (RESIDUAL, then restore) ----------
        svc_res = _predict_booster(svc_bst, multi_cols, mf)  # residual in log-space
        svc_base_med = get_base(baseline, "svc", key, "median", default=0.0)
        svc_log = float(np.log1p(max(0.0, svc_base_med)) + svc_res)
        svc_pred = max(0.0, float(np.expm1(svc_log)))

        # å´©å£Šé˜²æ­¢ï¼šbaselineã¸å¼·ãå¯„ã›ã€ã•ã‚‰ã«p95ã§ä¸Šé™
        svc_p95 = get_base(baseline, "svc", key, "p95", default=max(svc_base_med, svc_pred))
        svc_p05 = max(0.0, 0.6*svc_base_med)

        svc = 0.35*svc_pred + 0.65*svc_base_med
        svc = clip(svc, svc_p05, svc_p95)

        # ç‰©ç†ä¸Šé™ï¼šãã®æ ã§å‡¦ç†ã§ãã‚‹ã®ã¯ã€Œä»Šã„ã‚‹+å…¥ã‚‹ã€ã¾ã§
        svc = min(svc, queue_start + arr)

        # ---------- queue update ----------
        queue_end = max(0.0, queue_start + arr - svc)

        # ---------- wait mean/p90 ----------
        wm_log = _predict_booster(wait_bst, multi_cols, mf)
        wp_log = _predict_booster(wp90_bst, multi_cols, mf)
        wait_model = max(0.0, float(np.expm1(wm_log)))
        waitp90_model = max(0.0, float(np.expm1(wp_log)))

        # physics wait (calibrated)
        wait_phy = (queue_start + 0.5*arr) / max(svc, 1.0) * SLOT_MINUTES
        wait_phy = a*wait_phy + b

        alpha = alpha_peak if in_peak(ts) else alpha_base
        wait_med = get_base(baseline, "wait_mean", key, "median", default=wait_model)
        wait_p95 = get_base(baseline, "wait_mean", key, "p95", default=max(wait_model, wait_phy))

        wait_mean = alpha*wait_model + (1-alpha)*wait_phy
        wait_mean = 0.85*wait_mean + 0.15*wait_med
        wait_mean = clip(wait_mean, 0.0, wait_p95)

        wp95 = get_base(baseline, "wait_p90", key, "p95", default=max(waitp90_model, wait_mean))
        wait_p90 = 0.70*waitp90_model + 0.30*max(wait_phy, wait_mean)
        wait_p90 = clip(wait_p90, wait_mean, wp95)

        results.append({
            "æ™‚é–“å¸¯": ts.strftime("%H:%M"),
            "äºˆæ¸¬å—ä»˜æ•°": int(round(arr)),
            "äºˆæ¸¬å‡¦ç†æ•°(å‘¼å‡ºæ•°)": int(round(svc)),
            "äºˆæ¸¬å¾…ã¡äººæ•°_é–‹å§‹(äºº)": int(round(queue_start)),
            "äºˆæ¸¬å¾…ã¡äººæ•°_çµ‚äº†(äºº)": int(round(queue_end)),
            "äºˆæ¸¬å¹³å‡å¾…ã¡æ™‚é–“(åˆ†)": int(round(wait_mean)),
            "äºˆæ¸¬æ··é›‘æ™‚å¾…ã¡æ™‚é–“_p90(åˆ†)": int(round(wait_p90)),
        })

        # update state
        arr_lag_90, arr_lag_60, arr_lag_30 = arr_lag_60, arr_lag_30, arr
        svc_lag_90, svc_lag_60, svc_lag_30 = svc_lag_60, svc_lag_30, svc
        queue_start = queue_end

    return pd.DataFrame(results)

def main():
    st.set_page_config(page_title="Aç—…é™¢ æ¡è¡€ å¾…ã¡äººæ•°ãƒ»å¾…ã¡æ™‚é–“ äºˆæ¸¬", layout="wide")
    st.title("ğŸ¥ Aç—…é™¢ æ¡è¡€ å¾…ã¡äººæ•°ãƒ»å¾…ã¡æ™‚é–“ äºˆæ¸¬ï¼ˆæœ€çµ‚ç‰ˆï¼‰")
    st.caption("serviceæ®‹å·®ãƒ¢ãƒ‡ãƒ« + ä¿å­˜å‰‡ã‚­ãƒ¥ãƒ¼ + wait(ãƒ¢ãƒ‡ãƒ«/ç‰©ç†/baselineãƒ–ãƒ¬ãƒ³ãƒ‰)")

    with st.sidebar:
        st.header("å…¥åŠ›")
        target = st.date_input("äºˆæ¸¬å¯¾è±¡æ—¥", value=date.today() + timedelta(days=1))
        total_out = st.number_input("å»¶ã¹å¤–æ¥æ‚£è€…æ•°", min_value=0, value=1200, step=10)
        weather = st.selectbox("å¤©æ°—ï¼ˆç°¡æ˜“ï¼‰", ["æ™´", "æ›‡", "é›¨", "é›ª"], index=0)
        run = st.button("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ", type="primary")

        st.divider()
        st.subheader("å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆmodels/ï¼‰")
        st.write("- model_A_timeseries.json")
        st.write("- columns_A_timeseries.json")
        st.write("- model_A_service_30min.json")
        st.write("- model_A_waittime_30min.json")
        st.write("- model_A_waittime_p90_30min.json")
        st.write("- columns_A_multi_30min.json")
        st.write("- baseline_tables_mds.json")
        st.write("- wait_calibration.json")

    required = [
        ARR_MODEL_PATH, ARR_COLS_PATH,
        SVC_MODEL_PATH,
        WAIT_MODEL_PATH, WAITP90_MODEL_PATH,
        MULTI_COLS_PATH,
        BASELINE_PATH, CALIB_PATH
    ]
    missing = [p.name for p in required if not p.exists()]
    if missing:
        st.error("models/ ã«å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³ã—ã¦ã„ã¾ã™:\n\n" + "\n".join(missing))
        st.stop()

    if run:
        with st.spinner("è¨ˆç®—ä¸­..."):
            df = simulate_one_day(target, int(total_out), str(weather))
        st.success(f"{target} ã®äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

        c1, c2 = st.columns([2, 3], gap="large")
        with c1:
            st.subheader("çµæœãƒ†ãƒ¼ãƒ–ãƒ«")
            st.dataframe(df, use_container_width=True, hide_index=True)
            csv = df.to_csv(index=False, encoding="utf-8-sig")
            st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name=f"A_predict_{target}.csv", mime="text/csv")

        with c2:
            st.subheader("å¯è¦–åŒ–")
            st.line_chart(df.set_index("æ™‚é–“å¸¯")[["äºˆæ¸¬å¹³å‡å¾…ã¡æ™‚é–“(åˆ†)", "äºˆæ¸¬æ··é›‘æ™‚å¾…ã¡æ™‚é–“_p90(åˆ†)"]])
            st.bar_chart(df.set_index("æ™‚é–“å¸¯")[["äºˆæ¸¬å¾…ã¡äººæ•°_é–‹å§‹(äºº)"]])

if __name__ == "__main__":
    main()
