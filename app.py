import json
from pathlib import Path
from datetime import date, datetime, timedelta
import pandas as pd
import numpy as np
import streamlit as st
import xgboost as xgb

# ----------------------------
# 1. è¨­å®šãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
# ----------------------------
APP_DIR = Path(__file__).resolve().parent
MODELS_DIR = APP_DIR / "models"
DATA_DIR = APP_DIR / "data"

# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« (.ubj)
ARR_MODEL_PATH   = MODELS_DIR / "model_A_timeseries.ubj"
SVC_MODEL_PATH   = MODELS_DIR / "model_A_service_30min.ubj"
WAIT_MODEL_PATH  = MODELS_DIR / "model_A_waittime_30min.ubj"

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
ARR_COLS_PATH    = MODELS_DIR / "columns_A_timeseries.json"
MULTI_COLS_PATH  = MODELS_DIR / "columns_A_multi_30min.json"
BASELINE_PATH    = MODELS_DIR / "baseline_tables_mds.json"
CALIB_PATH       = MODELS_DIR / "wait_calibration.json"
HOLIDAY_CSV_PATH = DATA_DIR / "syukujitsu.csv"

OPEN_HOUR = 8
CLOSE_HOUR = 18
FREQ_MIN = 30
INCLUDE_CLOSE = False

# ----------------------------
# 2. å…±é€šãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ----------------------------
def _load_holidays() -> set:
    """ç¥æ—¥CSVã‚’èª­ã¿è¾¼ã‚€ï¼ˆæ–‡å­—ã‚³ãƒ¼ãƒ‰è‡ªå‹•åˆ¤åˆ¥ï¼‰"""
    if not HOLIDAY_CSV_PATH.exists(): return set()
    df = None
    for enc in ["cp932", "shift_jis", "utf-8", "utf-8-sig"]:
        try:
            df = pd.read_csv(HOLIDAY_CSV_PATH, encoding=enc, engine="python"); break
        except: continue
    if df is None: return set()
    
    col = next((c for c in df.columns if str(c).strip().lower() in ["date", "æ—¥ä»˜", "å›½æ°‘ã®ç¥æ—¥ãƒ»ä¼‘æ—¥æœˆæ—¥", "å¹´æœˆæ—¥"]), df.columns[0])
    return set(pd.to_datetime(df[col], errors="coerce").dropna().dt.date.tolist())

HOLIDAYS = _load_holidays()

def is_holiday(d: date) -> bool:
    if d.weekday() >= 5: return True
    if d in HOLIDAYS: return True
    if (d.month == 12 and d.day >= 29) or (d.month == 1 and d.day <= 3): return True
    return False

def week_of_month(d: date) -> int:
    return int((d.day - 1)//7 + 1)

def normalize_weather(s: str) -> str:
    t = str(s) if s else ""
    for w in ["é›ª", "é›¨", "æ›‡", "æ™´"]:
        if w in t: return w
    return "æ›‡"

def month_weekday_counts(y, m):
    start = pd.Timestamp(year=y, month=m, day=1)
    end = start + pd.offsets.MonthEnd(1)
    days = pd.date_range(start, end)
    counts = {k:int((days.dayofweek==k).sum()) for k in range(7)}
    return counts, sum(counts[k] for k in range(5))

@st.cache_resource
def load_artifacts():
    """ãƒ¢ãƒ‡ãƒ«ã¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰"""
    arr_cols = json.loads(ARR_COLS_PATH.read_text(encoding="utf-8"))
    multi_cols = json.loads(MULTI_COLS_PATH.read_text(encoding="utf-8"))
    
    # UBJSONå½¢å¼ã®èª­ã¿è¾¼ã¿
    arr_bst = xgb.Booster(); arr_bst.load_model(str(ARR_MODEL_PATH))
    svc_bst = xgb.Booster(); svc_bst.load_model(str(SVC_MODEL_PATH))
    wait_bst = xgb.Booster(); wait_bst.load_model(str(WAIT_MODEL_PATH))
    
    baseline = json.loads(BASELINE_PATH.read_text(encoding="utf-8"))
    calib = json.loads(CALIB_PATH.read_text(encoding="utf-8"))
    return arr_bst, arr_cols, svc_bst, wait_bst, multi_cols, baseline, calib

def _make_zero_df(cols):
    return pd.DataFrame({c: [0] for c in cols})

def _coerce_numeric(df):
    for c in df.columns:
        if df[c].dtype == "O": df[c] = pd.to_numeric(df[c], errors="coerce")
    return df.fillna(0)

def _predict_booster(bst, cols, df):
    X = _coerce_numeric(df[cols].copy())
    dmat = xgb.DMatrix(X, feature_names=list(cols))
    iter_range = (0, bst.best_iteration + 1) if getattr(bst, "best_iteration", None) else None
    return float(bst.predict(dmat, iteration_range=iter_range)[0])

def baseline_lookup(baseline, name, m, d, s):
    return float(baseline.get(name, {}).get(f"{int(m)}_{int(d)}_{int(s)}", 0.0))

def slot_index(ts):
    return int((ts.hour - OPEN_HOUR) * 2 + (ts.minute // 30))

def generate_slots(target_date):
    start = datetime.combine(target_date, datetime.min.time().replace(hour=OPEN_HOUR))
    end = datetime.combine(target_date, datetime.min.time().replace(hour=CLOSE_HOUR))
    rng = pd.date_range(start, end, freq=f"{FREQ_MIN}min")
    return [t.to_pydatetime() for t in rng if t.to_pydatetime() != end] if not INCLUDE_CLOSE else list(rng)

# ----------------------------
# 3. ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
# ----------------------------
def simulate_one_day(target_date, total_pat, weather_text, efficiency_rate=1.0):
    arr_bst, arr_cols, svc_bst, wait_bst, multi_cols, baseline, calib = load_artifacts()

    y, m, dow = target_date.year, target_date.month, target_date.weekday()
    is_h = int(is_holiday(target_date))
    prev_h = int(is_holiday(target_date - timedelta(days=1)))
    counts, w_total = month_weekday_counts(y, m)
    w_count, w_ratio = int(counts.get(dow, 0)), float(counts.get(dow, 0) / w_total) if w_total > 0 else 0.0
    wcat = normalize_weather(weather_text)

    # çŠ¶æ…‹å¤‰æ•°
    lags_arr = {"arr_lag_30":0.0, "arr_lag_60":0.0, "arr_lag_90":0.0}
    lags_svc = {"svc_lag_30":0.0, "svc_lag_60":0.0, "svc_lag_90":0.0}
    cum_arr, cum_svc, q_start = 0, 0, 0.0
    
    # è£œæ­£ä¿‚æ•°
    a, b = float(calib.get("a", 1.0)), float(calib.get("b", 0.0))
    alpha, floor_ratio = float(calib.get("alpha", 0.3)), float(calib.get("floor_ratio", 0.9))

    results = []
    
    for ts in generate_slots(target_date):
        slot = slot_index(ts)
        
        # --- ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
        def make_base_df(cols_list):
            df = _make_zero_df(cols_list)
            # Basic Features
            df.loc[0, "month"] = m
            df.loc[0, "dayofweek"] = dow
            df.loc[0, "is_holiday"] = is_h
            df.loc[0, "å‰æ—¥ç¥æ—¥ãƒ•ãƒ©ã‚°"] = prev_h
            df.loc[0, "æœˆ"] = m
            df.loc[0, "é€±å›æ•°"] = week_of_month(target_date)
            df.loc[0, "month_weekday_total"] = w_count
            df.loc[0, "weekday_count_in_month"] = w_count
            df.loc[0, "weekday_ratio_in_month"] = w_ratio
            df.loc[0, "total_outpatient_count"] = int(total_pat)
            
            # Weather
            df.loc[0, "é›¨ãƒ•ãƒ©ã‚°"] = 1 if "é›¨" in wcat else 0
            df.loc[0, "é›ªãƒ•ãƒ©ã‚°"] = 1 if "é›ª" in wcat else 0
            for c in ["æ™´", "æ›‡", "é›¨", "é›ª"]:
                if f"å¤©æ°—ã‚«ãƒ†ã‚´ãƒª_{c}" in df.columns: df.loc[0, f"å¤©æ°—ã‚«ãƒ†ã‚´ãƒª_{c}"] = 1 if c == wcat else 0
            
            # Time
            df.loc[0, "hour"] = ts.hour
            df.loc[0, "minute"] = ts.minute
            if f"dayofweek_{dow}" in df.columns: df.loc[0, f"dayofweek_{dow}"] = 1
            df.loc[0, "is_first_slot"] = 1 if (ts.hour==8 and ts.minute==0) else 0
            df.loc[0, "is_second_slot"] = 1 if (ts.hour==8 and ts.minute==30) else 0
            df.loc[0, "slot"] = slot
            
            # Dynamic State (Queue)
            df.loc[0, "queue_at_start_truth"] = float(q_start)
            if "queue_squared" in df.columns: 
                df.loc[0, "queue_squared"] = float(q_start) ** 2
            
            # Lags
            df.loc[0, "arr_lag_30"] = float(lags_arr["arr_lag_30"])
            df.loc[0, "arr_lag_60"] = float(lags_arr["arr_lag_60"])
            df.loc[0, "arr_lag_90"] = float(lags_arr["arr_lag_90"])
            df.loc[0, "arr_roll_60"] = float((lags_arr["arr_lag_30"]+lags_arr["arr_lag_60"])/2)
            df.loc[0, "svc_lag_30"] = float(lags_svc["svc_lag_30"])
            df.loc[0, "svc_lag_60"] = float(lags_svc["svc_lag_60"])
            df.loc[0, "svc_lag_90"] = float(lags_svc["svc_lag_90"])
            df.loc[0, "svc_roll_60"] = float((lags_svc["svc_lag_30"]+lags_svc["svc_lag_60"])/2)
            df.loc[0, "cum_arrivals"] = int(cum_arr)
            df.loc[0, "cum_service"] = int(cum_svc)
            
            # Baseline
            for t, n in [("arr_base", "arr_base"), ("svc_base", "svc_base"), ("wait_base", "wait_base")]:
                if n in df.columns: df.loc[0, n] = baseline_lookup(baseline, t, m, dow, slot)
            return df

        # --- 1. Arrivals Predict ---
        cf = make_base_df(arr_cols)
        # arr_diff ãªã©ã®å¾ªç’°å‚ç…§ç³»ã¯ã€Arrivalsäºˆæ¸¬æ™‚ç‚¹ã§ã¯å‰å›ã®å€¤or0ã‚’ä½¿ã†
        if "arr_diff" in cf.columns: cf.loc[0, "arr_diff"] = 0 
        arr_i = max(0, int(round(_predict_booster(arr_bst, arr_cols, cf))))

        # --- 2. Service & Wait Predict ---
        mf = make_base_df(multi_cols)
        
        # æ–°ç‰¹å¾´é‡ã®è¨ˆç®— (Arrivalsã®çµæœã‚’ä½¿ã£ã¦æ›´æ–°)
        if "arr_diff" in mf.columns:
            mf.loc[0, "arr_diff"] = float(arr_i) - float(lags_arr["arr_lag_30"])
        if "queue_density" in mf.columns:
            mf.loc[0, "queue_density"] = float(q_start) / (float(arr_i) + 1.0)

        # Service Predict
        raw_svc = _predict_booster(svc_bst, multi_cols, mf)
        svc_i = max(0, int(round(raw_svc * efficiency_rate))) # â˜…ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼åæ˜ 
        
        # â˜…å®‰å…¨è£…ç½®: è¡Œåˆ—ãŒã‚ã‚‹ãªã‚‰æœ€ä½1äººã¯å‡¦ç† (å¹½éœŠè¡Œåˆ—é˜²æ­¢)
        if q_start >= 0.5 and svc_i == 0: 
            svc_i = 1

        q_next = max(0.0, float(q_start) + float(arr_i) - float(svc_i))

        # Wait Predict (Log Transform -> expm1)
        raw_wait = _predict_booster(wait_bst, multi_cols, mf)
        pred_wait_ai = max(0.0, float(np.expm1(raw_wait)))
        
        # Physics Wait
        safe_svc = max(float(svc_i), 0.5)
        wait_phy = min((float(q_start) / safe_svc) * 30.0, 300.0)
        wait_phy_calib = max(0.0, a * wait_phy + b)
        
        # Ensemble
        wait_blend = alpha * pred_wait_ai + (1.0 - alpha) * wait_phy_calib
        
        # â˜…å®‰å…¨è£…ç½®: è¡Œåˆ—ãªã—ãªã‚‰å¾…ã¡æ™‚é–“0
        if q_start < 0.5:
            wait_final = 0.0
        else:
            # Baseline Floor
            wait_final = max(float(baseline_lookup(baseline, "wait_base", m, dow, slot))*floor_ratio, wait_blend)

        results.append({
            "æ™‚é–“å¸¯": ts.strftime("%H:%M"),
            "äºˆæ¸¬å—ä»˜æ•°": int(arr_i),
            "äºˆæ¸¬å‘¼å‡ºæ•°": int(svc_i),
            "äºˆæ¸¬å¾…ã¡äººæ•°": int(round(q_next)),
            "äºˆæ¸¬å¹³å‡å¾…ã¡æ™‚é–“(åˆ†)": int(round(wait_final))
        })

        # Update State
        lags_arr = {"arr_lag_30": float(arr_i), "arr_lag_60": lags_arr["arr_lag_30"], "arr_lag_90": lags_arr["arr_lag_60"]}
        lags_svc = {"svc_lag_30": float(svc_i), "svc_lag_60": lags_svc["svc_lag_30"], "svc_lag_90": lags_svc["svc_lag_60"]}
        cum_arr += int(arr_i)
        cum_svc += int(svc_i)
        q_start = q_next

    return pd.DataFrame(results)

# ----------------------------
# 4. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
# ----------------------------
def main():
    st.set_page_config(page_title="Aç—…é™¢ æ··é›‘äºˆæ¸¬", layout="wide")
    st.title("ğŸ¥ Aç—…é™¢ æ¡è¡€ å¾…ã¡æ™‚é–“äºˆæ¸¬AI")
    st.caption("Ver 7.2: High-Performance & Lightweight Model")

    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    required = [ARR_MODEL_PATH, SVC_MODEL_PATH, WAIT_MODEL_PATH, ARR_COLS_PATH, MULTI_COLS_PATH, BASELINE_PATH, CALIB_PATH]
    missing = [p.name for p in required if not p.exists()]
    if missing:
        st.error(f"ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚modelsãƒ•ã‚©ãƒ«ãƒ€ã‚’ç¢ºèªã—ã¦ãã ã•ã„:\n{', '.join(missing)}")
        st.stop()

    with st.sidebar:
        st.header("æ¡ä»¶è¨­å®š")
        tdate = st.date_input("äºˆæ¸¬æ—¥ä»˜", value=date.today() + timedelta(days=1))
        
        st.subheader("åŸºæœ¬æƒ…å ±")
        pat_num = st.number_input("äºˆæ¸¬å¤–æ¥æ‚£è€…æ•° (äºˆå®š)", value=1300, step=50, help="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸Šã®äºˆå®šäººæ•°")
        weather = st.selectbox("å¤©æ°—äºˆå ±", ["æ™´", "æ›‡", "é›¨", "é›ª"], index=1)
        
        st.divider()
        st.subheader("ç¾å ´çŠ¶æ³ã®èª¿æ•´")
        eff = st.slider("å‡¦ç†åŠ¹ç‡ (ã‚¹ã‚¿ãƒƒãƒ•ä½“åˆ¶)", 50, 120, 100, 5, 
                        help="100%=é€šå¸¸é€šã‚Šã€‚ã‚¹ã‚¿ãƒƒãƒ•æ¬ å“¡æ™‚ã‚„å‡¦ç½®é›£èˆªæ™‚ã¯80%ç¨‹åº¦ã«ä¸‹ã’ã¦ãã ã•ã„ã€‚")
        
        run = st.button("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹", type="primary")

    if run:
        with st.spinner("AIãŒäºˆæ¸¬ä¸­..."):
            df = simulate_one_day(tdate, int(pat_num), str(weather), eff/100.0)
        
        st.success(f"âœ… {tdate.strftime('%Y/%m/%d')} ã®äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸ")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        peak_wait = df["äºˆæ¸¬å¹³å‡å¾…ã¡æ™‚é–“(åˆ†)"].max()
        peak_time = df.loc[df["äºˆæ¸¬å¹³å‡å¾…ã¡æ™‚é–“(åˆ†)"].idxmax(), "æ™‚é–“å¸¯"]
        max_q = df["äºˆæ¸¬å¾…ã¡äººæ•°"].max()
        
        c1, c2, c3 = st.columns(3)
        c1.metric("æœ€å¤§å¾…ã¡æ™‚é–“", f"{peak_wait} åˆ†", f"@{peak_time}", delta_color="inverse")
        c2.metric("æœ€å¤§å¾…ã¡äººæ•°", f"{max_q} äºº")
        c3.metric("å—ä»˜æ•° / å‡¦ç†æ•°", f"{df['äºˆæ¸¬å—ä»˜æ•°'].sum()} / {df['äºˆæ¸¬å‘¼å‡ºæ•°'].sum()}")
        
        # ã‚°ãƒ©ãƒ•
        st.subheader("æ··é›‘æ¨ç§»ã‚°ãƒ©ãƒ•")
        st.line_chart(df.set_index("æ™‚é–“å¸¯")[["äºˆæ¸¬å¹³å‡å¾…ã¡æ™‚é–“(åˆ†)", "äºˆæ¸¬å¾…ã¡äººæ•°"]])
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        with st.expander("è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«"):
            st.dataframe(df.style.highlight_max(axis=0, color="#fffdc9"), use_container_width=True)
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, f"pred_{tdate}_eff{eff}.csv", "text/csv")

if __name__ == "__main__":
    main()
